
#!/bin/bash

#Make directory for variant calling within slate folder for project (/N/slate/emierdma/GSF3231)
mkdir Variantcall

samtools merge -@ 8 /N/slate/ealamb/GSF4155/variantcall/WTmerged.bam GSF4155-WT-input-rep1_S1_R1_001_Aligned.sortedByCoord.out.bam GSF4155-WT-input-rep2_S2_R1_001_Aligned.sortedByCoord.out.bam  GSF4155-WT-input-rep3_S3_R1_001_Aligned.sortedByCoord.out.bam
samtools merge -@ 8 /N/slate/ealamb/GSF4155/variantcall/ADR2merged.bam GSF4155-adr-2-input-rep1_S7_R1_001_Aligned.sortedByCoord.out.bam GSF4155-adr-2-input-rep2_S8_R1_001_Aligned.sortedByCoord.out.bam GSF4155-adr-2-input-rep3_S9_R1_001_Aligned.sortedByCoord.out.bam
samtools merge -@ 8 /N/slate/ealamb/GSF4155/variantcall/HAEmerged.bam GSF4155-HAE-input-rep1_S13_R1_001_Aligned.sortedByCoord.out.bam GSF4155-HAE-input-rep3_S14_R1_001_Aligned.sortedByCoord.out.ba


#remove duplicate reads from bam file (takes ~5 minutes per file)
samtools rmdup WTmerged.bam WT.nodup.bam
samtools rmdup ADR2merged.bam ADR2.nodup.bam
samtools rmdup HAEmerged.bam HAE.nodup.bam


#Call the variant and clean up the output file
bcftools mpileup -Ou -f assembly.fasta -a DP4 HAE.nodup.bam \
  | bcftools call -m -A -Ov \
  | awk '$5 != "<*>"' \
  | tail -n +30 > corrHAE.rmdup.mpileup.vcf

bcftools mpileup -Ou -f assembly.fasta -a DP4 WT.nodup.bam \
  | bcftools call -m -A -Ov \
  | awk '$5 != "<*>"' \
  | tail -n +30 > corrWT.rmdup.mpileup.vcf


bcftools mpileup -Ou -f assembly.fasta -a DP4 ADR2.nodup.bam \
  | bcftools call -m -A -Ov \
  | awk '$5 != "<*>"' \
  | tail -n +30 > corrADR2.rmdup.mpileup.vcf


#copy variant.py file into Variantcall directory (in terminal, off carbonate)
#convert vcf files to csv to open in excel
python3 variant_updatedEL080825.py --v corrHAE.rmdup.mpileup.vcf --o corrHAEvariant.csv 
python3 variant_updatedEL080825.py --v corrWT.rmdup.mpileup.vcf --o corrWTvariant.csv 
python3 variant_updatedEL080825.py --v corrADR2.rmdup.mpileup.vcf --o corrADR2variant.csv 


#open csv in R studio to see how many rows it has
library("tidyverse")
library("GenomicRanges")
variants <- read.csv("/Users/emmalamb/Desktop/Bioinformatics/corrHAEvariant.csv")
View(variants)

#if the table is >1,000,000 rows, the csv will not open in excel and needs to be split into parts


#In RStudio :


# Load required package
library(dplyr)

# Read the reference file
reference <- read.csv("SDreference.csv", stringsAsFactors = FALSE)

# Function to filter variant files based on reference positions
filter_variants <- function(variant_file, output_file) {
  variants <- read.csv(variant_file, stringsAsFactors = FALSE)
  
  # Filter rows where chr and pos match Chromosome and Position in reference
  filtered <- variants %>%
    semi_join(reference, by = c("chr" = "Chromosome", "pos" = "Position"))
  
  # Write filtered data to new CSV
  write.csv(filtered, output_file, row.names = FALSE)
  
  message(paste("Filtered data saved to", output_file))
}

# Run the function for each variant file
filter_variants("corrHAEvariant.csv", "filtered_corrHAEvariant.csv")
filter_variants("corrWTvariant.csv", "filtered_corrWTvariant.csv")
filter_variants("corrADR2variant.csv", "filtered_corrADR2variant.csv")
